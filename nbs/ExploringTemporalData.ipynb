{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExploringTemporalData\n",
    "**Eli Simic Robertson**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import random\n",
    "import networkx as nx \n",
    "import matplotlib.pyplot as plt \n",
    "import collections\n",
    "import os\n",
    "\n",
    "# deprecation warnings\n",
    "import warnings\n",
    "import matplotlib.cbook\n",
    "warnings.filterwarnings(\"ignore\",category=matplotlib.cbook.mplDeprecation)\n",
    "\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating My Own Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "body_constr = [0,20]\n",
    "head_constr = [0,10]\n",
    "max_root_time = 100000 - head_constr[1]\n",
    "\n",
    "# BODY_CONST = 'body'\n",
    "HEAD_CONST = 'head'\n",
    "ROOT_CONST = 'r'\n",
    "A = 'a'\n",
    "always = 100\n",
    "cycle_prob = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def time_interval(body_constr): return tuple(np.random.uniform(body_constr)) \n",
    "\n",
    "def unique_body_symbols(low=3, high=5, single=False):\n",
    "    '''Creates a random unique list of symbols for the body \n",
    "    of pattern. Symbol A has been excluded from the list as it is reserved \n",
    "    for the head of the pattern.\n",
    "        Args: \n",
    "            n_body_symbols (int): amount of body symbols\n",
    "            \n",
    "        Returns:\n",
    "            random_symbols (list): random choice of symbols\n",
    "    '''\n",
    "    symbols = ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k'] # possible body symbols\n",
    "    n_bod_symbols = np.random.randint(low, high)\n",
    "    if single:  n_bod_symbols = 1 \n",
    "    rand_symbols = random.sample(symbols, k=n_bod_symbols)\n",
    "    \n",
    "    return rand_symbols\n",
    "\n",
    "def make_edges(Edge, body_symbols, condition=None, connected_nodes=None):\n",
    "    '''Args:\n",
    "            Edge (named_tuple): Edge object with default fields.\n",
    "            body_symbols (list): unique body symbols.\n",
    "            condition (str/logical???): Conditional operator, if any.\n",
    "            connected_nodes (list): list of currently connected nodes to \n",
    "            graph object.\n",
    "        Returns:\n",
    "            edges (list of named_tuples): \n",
    "            connected_nodes (list): \n",
    "            \n",
    "    '''\n",
    "    \n",
    "    if condition == 'conjunction' or condition == 'disjunction':\n",
    "        n_body_symbols = 2\n",
    "    elif condition == 'negation' or condition == 'cycle':\n",
    "        n_body_symbols = 1\n",
    "    elif condition == None:\n",
    "        n_body_symbols = len(body_symbols)\n",
    "    \n",
    "    edges = []\n",
    "    if connected_nodes is None: connected_nodes = []\n",
    "    \n",
    "    for _ in range(n_body_symbols):\n",
    "        sym = body_symbols.pop()\n",
    "        start_t, end_t = time_interval(body_constr)\n",
    "        rand_end_s = np.random.choice(connected_nodes + [ROOT_CONST])        \n",
    "\n",
    "        if condition == 'disjunction':\n",
    "            ### HANDLE Low > High error\n",
    "            edges.append(Edge(ROOT_CONST, sym, start_t, end_t, prob=always, disjunction=True))\n",
    "            connected_nodes.append(sym)\n",
    "        elif condition == 'conjunction':\n",
    "            edges.append(Edge(ROOT_CONST, sym, start_t, end_t, prob=always, conjunction=True))\n",
    "            connected_nodes.append(sym)\n",
    "        elif condition == 'negation':\n",
    "            edges.append(Edge(rand_end_s, sym, start_t, end_t, prob=always, negation=True))\n",
    "            connected_nodes.append(sym)\n",
    "        elif condition == 'cycle':\n",
    "            edges.append(Edge(rand_end_s, sym, start_t, end_t, prob=cycle_prob, cycle=True))\n",
    "            connected_nodes.append(sym)\n",
    "        # no conditional operator, append edge to connected nodes or root\n",
    "        elif condition == None:\n",
    "            edges.append(Edge(rand_end_s, sym, start_t, end_t, prob=always))\n",
    "            connected_nodes.append(sym)\n",
    "\n",
    "    return edges, connected_nodes\n",
    "\n",
    "def body_pattern(low_body=4, high_body=6, low_prob=60, high_prob=90, disjunction=False,\n",
    "                   negation=False, conjunction=False, prob=always, cycle=False):\n",
    "    \n",
    "    body_symbols = unique_body_symbols(low_body, high_body) # technically, body_symbols excluding root\n",
    "    rand_num = np.random.uniform(low=0, high=always)\n",
    "    prob = np.random.uniform(low=low_prob, high=high_prob)\n",
    "    connected_nodes = [ROOT_CONST] # keep track of connected nodes for end_symbol possibilities\n",
    "    \n",
    "    pattern = [] # pattern list of edges : graph like object\n",
    "    fields = ('start_s', 'end_s', 'start_t', 'end_t', 'disjunction', 'negation', 'conjunction', 'cycle', 'prob')\n",
    "    Edge = collections.namedtuple('Edge', fields)\n",
    "    Edge.__new__.__defaults__ = (False,) * len(Edge._fields) # set default fields\n",
    "\n",
    "        \n",
    "    if disjunction:\n",
    "        \n",
    "        max_disjs = len(body_symbols) // 2\n",
    "        n_disjs = np.random.randint(low=1, high=max_disjs)\n",
    "        for disj in range(n_disjs): \n",
    "            edges, nodes = make_edges(Edge, body_symbols, condition='disjunction')\n",
    "            pattern.append(Edge(nodes[0], nodes[1], # disjunction edge\n",
    "                start_t=None, end_t=None, disjunction=True, prob=always))\n",
    "            pattern.extend(edges)\n",
    "            connected_nodes.extend(nodes)\n",
    "\n",
    "    if cycle:\n",
    "        edges, nodes = make_edges(Edge, body_symbols, condition='cycle') # create cycle edge\n",
    "        pattern.append(Edge(nodes[0], np.random.choice(connected_nodes),\n",
    "                           disjunction=True)) # create disjunction edge to stop infinite loop\n",
    "        pattern.extend(edges)\n",
    "        connected_nodes.extend(nodes) \n",
    "        \n",
    "    elif negation:\n",
    "        edges, nodes = make_edges(Edge, body_symbols, condition='negation',\n",
    "                                 connected_nodes=connected_nodes)\n",
    "        pattern.extend(edges)\n",
    "        connected_nodes.extend(nodes) \n",
    "        \n",
    "    elif conjunction:\n",
    "        edges, nodes = make_edges(Edge, body_symbols, condition='conjunction')\n",
    "        pattern.extend(edges)\n",
    "        connected_nodes.extend(nodes)\n",
    "    # remaining nodes are added to either root or connected body node\n",
    "    edges, nodes = make_edges(Edge, body_symbols, condition=None,\n",
    "                             connected_nodes=connected_nodes)\n",
    "    pattern.extend(edges)\n",
    "    connected_nodes.extend(nodes)\n",
    "\n",
    "    return pattern\n",
    "\n",
    "def plot_pattern(pattern): # sometimes returns None? unsure why. annoying\n",
    "    G = GraphVisualization() \n",
    "    for p in pattern: G.addEdge(p.start_s, p.end_s) \n",
    "    G.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Training Set\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_point(start_t, end_t): return np.random.uniform(start_t, end_t)\n",
    "\n",
    "def generate_edge_instance(tp,edge):\n",
    "    return tp - time_point(edge.start_t, edge.end_t), edge.end_s\n",
    "\n",
    "def outgoing_edges(node, pattern):\n",
    "    '''Find immediate edges for a node'''\n",
    "    out_edges = []\n",
    "    for edge in pattern:            \n",
    "        if edge.disjunction and edge.start_t is None: continue\n",
    "            \n",
    "        elif edge.negation == True: continue # skip negation node        \n",
    "            \n",
    "        elif edge.start_s == node:            \n",
    "            out_edges.append(edge)\n",
    "\n",
    "    return out_edges\n",
    "\n",
    "def dest_nodes(node,pattern):\n",
    "    out_edges = outgoing_edges(node,patt)\n",
    "    return [edge.end_s for edge in out_edges]\n",
    "    \n",
    "def mutual_excl_edges(pattern):\n",
    "    '''Find all mutually exclusive edges in pattern'''\n",
    "    return [e for e in pattern if e.start_t == None]\n",
    "\n",
    "def have_mutual(node, excl_edges):\n",
    "    '''Is a given node connected to a mutually exclusive node'''\n",
    "    for edge in excl_edges:\n",
    "        if node == edge.start_s or node == edge.end_s:\n",
    "            return True\n",
    "        \n",
    "    else: False\n",
    "        \n",
    "def generate_neighbouring_tps(node,tp,patt):\n",
    "    out_edges = outgoing_edges(node,patt)\n",
    "    excl_edges = mutual_excl_edges(patt)\n",
    "\n",
    "    # determine which edge to choose from each mutual exclusion\n",
    "    skip_nodes = []\n",
    "    for edge in excl_edges:\n",
    "        if np.random.randint(2) == 1:\n",
    "            skip_nodes.append(edge.start_s)\n",
    "        else:\n",
    "            skip_nodes.append(edge.end_s)\n",
    "\n",
    "    tps = []\n",
    "    for edge in out_edges:\n",
    "        if edge.prob != 100 and rand_num > 50: continue\n",
    "        elif edge.end_s in skip_nodes: continue\n",
    "        tps.append(generate_edge_instance(tp,edge))\n",
    "        \n",
    "    return tps\n",
    "        \n",
    "        \n",
    "def generate_tps(node,tp,patt):\n",
    "    all_tps = []\n",
    "\n",
    "    if node == None:\n",
    "        # this is the start of recursive generation, start from root\n",
    "        node = ROOT_CONST\n",
    "        tp = np.random.uniform(low=0, high=max_root_time)\n",
    "        all_tps.append((tp, node))\n",
    "    \n",
    "    neighbouring_tps = generate_neighbouring_tps(node,tp,patt)\n",
    "    all_tps += neighbouring_tps\n",
    "    \n",
    "    for neighbouring_tp in neighbouring_tps:\n",
    "        # recursive step (because calling this same method)\n",
    "       all_tps += generate_tps(neighbouring_tp[1],neighbouring_tp[0],patt)\n",
    "    \n",
    "    return all_tps\n",
    "\n",
    "def generate_event_pred(patt, make_pred=False):\n",
    "    '''\n",
    "    For event instance, only add A if head prob is exceeded\n",
    "    Input: \n",
    "    Returns: \n",
    "    '''\n",
    "\n",
    "    \n",
    "    body_patt = patt[0]\n",
    "    head_patt = patt[1]\n",
    "    \n",
    "    if make_pred == False:\n",
    "        body_patt = rand_subset(patt[0])\n",
    "    \n",
    "    body_inst = generate_tps(None, None, body_patt)\n",
    "\n",
    "    pred = []\n",
    "    \n",
    "    for t in body_inst: # get root tp\n",
    "        if t[1] == ROOT_CONST: \n",
    "            root_tp = t[0]\n",
    "        \n",
    "    head_tp = root_tp + time_point(head_patt[1], head_patt[2])    \n",
    "    consequent = (head_tp, A)\n",
    "    pred.append(consequent)\n",
    "        \n",
    "    if head_prob > np.random.randint(low=0, high=100):\n",
    "        body_inst.append(consequent) \n",
    "\n",
    "    if make_pred:\n",
    "        return body_inst, pred\n",
    "\n",
    "    else:\n",
    "        return body_inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rand_subset(body_patt): # random subset of the instance\n",
    "    '''\n",
    "    Returns:\n",
    "        ts (list): list of lists of time point and symbol of\n",
    "        random subset of the pattern definition'''\n",
    "    if len(body_patt) == 1: return []\n",
    "    \n",
    "    subset_idxs = sorted([np.random.randint(low=0, high=len(body_patt)) for _ in range(2)])\n",
    "    sub_pattern = body_patt[subset_idxs[0]: subset_idxs[1]]\n",
    "    \n",
    "    return sub_pattern\n",
    "    \n",
    "def noisy_instance(time_high=100000):\n",
    "    ''' Input: \n",
    "            time_high (int): \n",
    "    \n",
    "            Returns:\n",
    "                ts (list): list of lists containing random time point and symbol'''\n",
    "    \n",
    "    sym = unique_body_symbols(single=True).pop()\n",
    "    tp = time_point(start_t=0, end_t=time_high)\n",
    "    inst = [[tp, sym]]\n",
    "    return inst\n",
    "\n",
    "def generate_events_preds(pattern, n_patterns, n_subsets, n_noisy_insts):\n",
    "    '''Creates both .event array and its corresponding .pred array from\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "            events (list): time series for training/testing set\n",
    "            preds (list): ground truth values\n",
    "    '''\n",
    "\n",
    "    \n",
    "    events, preds= [], []\n",
    "    \n",
    "    for _ in range(n_patterns):\n",
    "        event, pred =  generate_event_pred(pattern, make_pred=True)\n",
    "        events.extend(event)\n",
    "        preds.extend(pred)\n",
    "        \n",
    "    for _ in range(n_subsets):\n",
    "        event = generate_event_pred(pattern, make_pred=False) # \n",
    "        if event == None:\n",
    "            continue\n",
    "        elif event != []:\n",
    "            events.extend(event)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    for _ in range(n_noisy_insts):\n",
    "        event = noisy_instance()\n",
    "        events.extend(event)\n",
    "        \n",
    "\n",
    "    events.sort(key=lambda x: x[0])\n",
    "    preds.sort(key=lambda x: x[0])# sort by timestamp\n",
    "    \n",
    "    return events, preds\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Create Event File. Create related Pred file. Create log file (HTML??).\n",
    "'''\n",
    "\n",
    "ROOT_DIR = 'C:/Users/admin/Documents/TemporalDataGeneration/'\n",
    "\n",
    "def make_event_dir():\n",
    "    os.chdir(f\"{ROOT_DIR}/data/\")\n",
    "\n",
    "    event_id = 0\n",
    "    while os.path.exists(f\"./pattern_{event_id}\"):\n",
    "        event_id += 1\n",
    "\n",
    "    new_dir = f\"../data/pattern_{event_id}\"\n",
    "\n",
    "    os.mkdir(new_dir)    \n",
    "    os.chdir(new_dir)\n",
    "    \n",
    "    return event_id\n",
    "\n",
    "def array_to_file(file_name, array, log=False):\n",
    "    with open(file_name, 'w') as file:\n",
    "        for l in array:\n",
    "            if log:\n",
    "                file.write(str(l) + '\\n') \n",
    "            else:\n",
    "                s = str(l[0]) + \" \" + str(l[1]) + '\\n'\n",
    "                file.write(s)\n",
    "                \n",
    "def make_learning_config(pattern_path, event_id):\n",
    "    xml = ET.parse(f'{ROOT_DIR}/titarl_learning_config.xml')\n",
    "    root = xml.getroot()\n",
    "    \n",
    "    for child in root:\n",
    "        if child.get('name') == 'saveRules_new':\n",
    "            ## WEIRD UNICODE BUG? sometimes outputs pattern_14&#10;ew_rules_14.xml\n",
    "            print(child.set('value', f'{pattern_path}\\\\new_rules_{event_id}.xml'))\n",
    "\n",
    "        if child.get('path'):\n",
    "            child.set('path', f'{pattern_path}\\pattern_{event_id}.evt')\n",
    "        \n",
    "    xml.write(f'./pattern_{event_id}_learning_config.xml')\n",
    "    \n",
    "\n",
    "def make_patt_files(pattern, events1, preds1, events2, preds2):\n",
    "    event_id = make_event_dir() # now set to individual pattern directory\n",
    "    \n",
    "#     print(os.getcwd())\n",
    "    \n",
    "    pattern_path = os.getcwd()\n",
    "    \n",
    "    array_to_file(f'{pattern_path}\\pattern_{event_id}.log', pattern, log=True) # log the pattern\n",
    "    \n",
    "    array_to_file(f'{pattern_path}\\pattern_{event_id}_1.evt', events1)\n",
    "    array_to_file(f'{pattern_path}\\pattern_{event_id}_1.pred', preds1) # write preds to .pred file\n",
    "\n",
    "    \n",
    "    array_to_file(f'{pattern_path}\\pattern_{event_id}_2.evt', events2)\n",
    "    array_to_file(f'{pattern_path}\\pattern_{event_id}_2.pred', preds2) # write preds to .pred file\n",
    "    \n",
    "    make_learning_config(pattern_path, event_id)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "body_patt = body_pattern(low_body=1, high_body=2)\n",
    "\n",
    "def make_pattern(body_patt):\n",
    "    start_t, end_t = time_interval(head_constr)\n",
    "    consequent = tuple([A, start_t, end_t])\n",
    "\n",
    "    return (body_patt, consequent)\n",
    "\n",
    "patt = make_pattern(body_patt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# patt = body_pattern(low_body=4, high_body=6, low_prob=60, high_prob=90,\n",
    "#              disjunction=False, negation=False, conjunction=False, prob=100, cycle=False)\n",
    "\n",
    "n_patterns = 1000\n",
    "n_subsets = 5000\n",
    "n_noisy_insts = 0\n",
    "head_prob = 60\n",
    "\n",
    "def generate_pattern_files():\n",
    "\n",
    "    events1, preds1 = generate_events_preds(pattern=patt, n_patterns=n_patterns,\n",
    "                                   n_subsets=n_subsets, n_noisy_insts=n_noisy_insts)\n",
    "    \n",
    "    events2, preds2 = generate_events_preds(pattern=patt, n_patterns=n_patterns,\n",
    "                               n_subsets=n_subsets, n_noisy_insts=n_noisy_insts)\n",
    "\n",
    "    make_patt_files(patt, events1, preds1, events2, preds2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "generate_pattern_files()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
